{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.learner import *\n",
    "from fastai.basic_data import DataBunch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the dataset\n",
    "#export\n",
    "#special tokens\n",
    "UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ = \"xxunk xxpad xxbos xxeos xxrep xxwrep xxup xxmaj\".split()\n",
    "\n",
    "def sub_n(t):\n",
    "    \"Replaces the \\n by space\"\n",
    "    re_br = re.compile(r'\\n', re.IGNORECASE)\n",
    "    return re_br.sub(\" \", t)\n",
    "\n",
    "def spec_add_spaces(t):\n",
    "    \"Add spaces around / # , . ; :\"\n",
    "    return re.sub(r'([/#,.;:])', r' \\1 ', t)\n",
    "\n",
    "def rm_useless_spaces(t):\n",
    "    \"Remove multiple spaces\"\n",
    "    return re.sub(' {2,}', ' ', t)\n",
    "\n",
    "def replace_rep(t):\n",
    "    \"Replace repetitions at the character level: cccc -> TK_REP 4 c\"\n",
    "    def _replace_rep(m:str):\n",
    "        c,cc = m.groups()\n",
    "        return f' {TK_REP} {len(cc)+1} {c} '\n",
    "    re_rep = re.compile(r'(\\S)(\\1{3,})')\n",
    "    return re_rep.sub(_replace_rep, t)\n",
    "\n",
    "def replace_section_number(t):\n",
    "    \"Replace section numbers by NEWSECTION\"\n",
    "    return re.sub(r'(\\d+:\\d+)', 'NEWSECTION', t)\n",
    "\n",
    "def sep_special(t):\n",
    "    return re.sub(r'[\\.,]', '  ', t)\n",
    "    \n",
    "def fixup_text(x):\n",
    "    \"Various messy things we've seen in documents\"\n",
    "    re1 = re.compile(r'  +')\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>',UNK).replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "    \n",
    "default_pre_rules = [fixup_text,  replace_section_number, spec_add_spaces, replace_rep\n",
    "                     , sub_n]\n",
    "default_spec_tok = [UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process the data\n",
    "def read_and_tokenize():\n",
    "    data = open('input_bible.txt', 'r').read()\n",
    "    data = data.lower()\n",
    "    for rule in default_pre_rules:\n",
    "        data = rule(data)\n",
    "    data = rm_useless_spaces(data)\n",
    "    return data\n",
    "\n",
    "df = read_and_tokenize().split()\n",
    "vocab = Counter(df)\n",
    "vocab = [k for k in vocab.keys()]\n",
    "word_to_ix  = {wr:i for i,wr in enumerate(vocab)}\n",
    "ix_to_word = {i:wr for i,wr in enumerate(vocab)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a data loader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#create a custom data dataset / dataloader\n",
    "class bible_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, seq_len):\n",
    "        self.df = read_and_tokenize().split()\n",
    "        self.vocab = Counter(self.df)\n",
    "        self.vocab = [k for k in self.vocab.keys()]\n",
    "        self.word_to_ix  = {wr:i for i,wr in enumerate(self.vocab)}\n",
    "        self.ix_to_word = {i:wr for i,wr in enumerate(self.vocab)}        \n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.vocab)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (np.array([self.word_to_ix[wrd] for wrd in self.df[idx:idx+self.seq_len]]),\n",
    "                np.array([self.word_to_ix[wrd] for wrd in self.df[idx+1:idx+self.seq_len+1]]))\n",
    "seq_len=10\n",
    "bible_df = DataLoader(bible_dataset(seq_len), 1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode over the whole vocab\n",
    "def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n",
    "    # Creating a multi-dimensional array of zeros with the desired output shape\n",
    "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
    "    \n",
    "    # Replacing the 0 at the relevant character index with a 1 to represent that character\n",
    "    for i in range(batch_size):\n",
    "        for u in range(seq_len):\n",
    "            features[i, u, sequence[i][u]] = 1\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "class CyclicLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]\n",
    "    \n",
    "def cosine(t_max, eta_min=0):  \n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + math.cos(math.pi*t/t_max))/2\n",
    "    \n",
    "    return scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60002\n"
     ]
    }
   ],
   "source": [
    "from fastai.text import *\n",
    "awd_lstm_clas_config = dict(emb_sz=400, n_hid=1150, n_layers=3, pad_token=1, qrnn=False, bidir=False, output_p=0.4,\n",
    "                       hidden_p=0.2, input_p=0.6, embed_p=0.1, weight_p=0.5, tie_weights=None, out_bias=1)\n",
    "awd_lstm_model = get_language_model(arch=AWD_LSTM,config=awd_lstm_clas_config, vocab_sz=len(bible_df))\n",
    "old_wgts  = torch.load('models/pretrained/lstm_wt103.pth', map_location='cpu')\n",
    "old_vocab = pickle.load(open('models/pretrained/itos_wt103.pkl', 'rb'))\n",
    "print(len(old_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match vocab overlap \n",
    "def match_embeds(old_wgts, old_vocab, new_vocab):\n",
    "    wgts = old_wgts['0.encoder.weight']\n",
    "    bias = old_wgts['1.decoder.bias']\n",
    "    wgts_m,bias_m = wgts.mean(dim=0),bias.mean()\n",
    "    new_wgts = wgts.new_zeros(len(word_to_ix), wgts.size(1))\n",
    "    new_bias = bias.new_zeros(len(word_to_ix))\n",
    "    otoi = {v:k for k,v in enumerate(old_vocab)}\n",
    "    for i,w in enumerate(word_to_ix): \n",
    "        if w in otoi:\n",
    "            idx = otoi[w]\n",
    "            new_wgts[i],new_bias[i] = wgts[idx],bias[idx]\n",
    "        else: new_wgts[i],new_bias[i] = wgts_m,bias_m\n",
    "    old_wgts['0.encoder.weight']    = new_wgts\n",
    "    old_wgts['0.encoder_dp.emb.weight'] = new_wgts\n",
    "    old_wgts['1.decoder.weight']    = new_wgts\n",
    "    old_wgts['1.decoder.bias']      = new_bias\n",
    "    return old_wgts\n",
    "wgts = match_embeds(old_wgts, old_vocab, word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awd_lstm_model.load_state_dict(wgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the AWD LSTM model with the trained weights\n",
    "def load_model():\n",
    "    awd_lstm_lm_config = dict(emb_sz=400, n_hid=1150, n_layers=3, pad_token=1, qrnn=False, bidir=False, output_p=0.1,\n",
    "                       hidden_p=0.15, input_p=0.25, embed_p=0.02, weight_p=0.2, tie_weights=True, out_bias=True)\n",
    "    awd_lstm_model = get_language_model(arch=AWD_LSTM,config=awd_lstm_lm_config, vocab_sz=len(bible_df))\n",
    "    wgts  = torch.load('pretrained_unfrozen.pth', map_location='cpu')\n",
    "    awd_lstm_model.load_state_dict(wgts)\n",
    "    return awd_lstm_model\n",
    "awd_lstm_model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 35\n",
    "\n",
    "# Sample from a category and starting word\n",
    "def sample(start_word='NEWSECTION'):\n",
    "    awd_lstm_model.reset()\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        input = torch.from_numpy(np.array([[word_to_ix[start_word]]]))\n",
    "        #make the newsection word realistic\n",
    "        if start_word == 'NEWSECTION':\n",
    "            start_word = str(random.choice(range(0,20))) + ':' + str(random.choice(range(0,100)))\n",
    "        output_name = start_word + ' '\n",
    "\n",
    "        for i in range(max_length):\n",
    "            output, hidden1,hidden2 = awd_lstm_model(input.long())\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            if topi == len(vocab) - 1:\n",
    "                break\n",
    "            else:\n",
    "                next_word = vocab[topi]\n",
    "                output_name += next_word + ' '\n",
    "            input = torch.from_numpy(np.array([[word_to_ix[next_word]]]))\n",
    "        return output_name     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jesus , who was a member of the two . the first . the new head of the new south , the new of the new league . the new new new life , which was '"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample('jesus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_words = ['NEWSECTION', 'the']\n",
    "\n",
    "def sample_ext():\n",
    "\n",
    "def sentence_tensor():\n",
    "\n",
    "    tensor = torch.zeros(len(pre_words))\n",
    "    for p_word in range(len(pre_words)):\n",
    "        tensor[p_word] = word_to_ix[pre_words[p_word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2.])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.from_numpy(np.array([[word_to_ix['NEWSECTION']]]))\n",
    "[[word_to_ix['NEWSECTION']]]\n",
    "pre_words = ['NEWSECTION', 'the']\n",
    "tensor = torch.zeros(len(pre_words))\n",
    "for p_word in range(len(pre_words)):\n",
    "    tensor[p_word] = word_to_ix[pre_words[p_word]]\n",
    "tensor    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-206-a21fc35a82ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp_word\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#     word = pre_words[p_word]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp_word\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp_word\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "tensor = torch.zeros(len(pre_words))\n",
    "for p_word in range(len(pre_words)):\n",
    "#     word = pre_words[p_word]\n",
    "    tensor[p_word] = word_to_ix[pre_words[p_word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NEWSECTION', 0)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.zeros(len(pre_words))\n",
    "# tensor[word_to_ix[p_word]] = [word_to_ix[p_word]]\n",
    "pre_words[p_word], word_to_ix[pre_words[p_word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:48\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(str(random.choice(range(0,20))) + ':' + str(random.choice(range(0,100))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
