{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip \n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "#http://jmcauley.ucsd.edu/data/amazon/\n",
    "#CDs and Vinyl 5-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "metadata = getDF('meta_CDs_and_Vinyl.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['productType'] = metadata['salesRank'].apply(lambda x: [str(i) for i in x][0] if len(str(x))>4 else '')\n",
    "metadata['genre'] = metadata['categories'].apply(lambda x: str(x).replace(']', '').split(', ')[1].replace(\"'\", '')\n",
    "                                                                                   if len(str(x).replace(']', '').split(', '))>1 \n",
    "                                                                                    else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('merged_album_data.pkl')\n",
    "#null album titles are no use for us\n",
    "a = a[~(a['title'].isnull())]\n",
    "a = a[['reviewerID', 'asin', 'title']].drop_duplicates(subset=['reviewerID', 'title'])\n",
    "a = a.merge(metadata[['title', 'genre']], on='title', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36162, 42417)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_gen_counts = a[['title', 'genre']].drop_duplicates().groupby('title')['genre'].count().rename('n').reset_index()\n",
    "prod_gen_onetoone = prod_gen_counts[prod_gen_counts['n']==1]\n",
    "len(prod_gen_onetoone),len(prod_gen_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop products with more than 1 genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a[a['title'].isin(prod_gen_onetoone['title'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_list = a['reviewerID'].unique()\n",
    "users_index = {user: idx for idx, user in enumerate(users_list)}\n",
    "#tranform each prod into an index\n",
    "prod_list = a['title'].unique()\n",
    "prod_index = {prod: idx for idx, prod in enumerate(prod_list)}\n",
    "#genre index\n",
    "genre_list = a['genre'].unique()\n",
    "genre_index = {genre: idx for idx, genre in enumerate(genre_list)}\n",
    "a = a[['reviewerID', 'asin','title', 'genre']]\n",
    "a['reviewerID'] = a['reviewerID'].apply(lambda x: users_index[x]).astype('int')\n",
    "a['prodID'] = a['title'].apply(lambda x: prod_index[x]).astype('int')\n",
    "music_index = dict(zip(a['title'], a['prodID']))\n",
    "a['genreID'] = a['genre'].apply(lambda x: genre_index[x]).astype('int')\n",
    "a = a[['reviewerID', 'prodID', 'genreID']]\n",
    "a = a.drop_duplicates(subset=['reviewerID', 'prodID', 'genreID'])\n",
    "a['purchase_flag'] = 1\n",
    "prod_genre = a[['prodID', 'genreID']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function used from https://medium.com/@2j/negative-sampling-in-numpy-18a9ad810385\n",
    "def negsamp_vectorized_bsearch(pos_inds, n_items, n_samp=32):\n",
    "    raw_samps = np.random.randint(0, n_items, size=n_samp)\n",
    "    ss = np.searchsorted(pos_inds, raw_samps)\n",
    "    pos_mask = raw_samps == np.take(pos_inds, ss, mode='clip')\n",
    "    neg_inds = raw_samps[~pos_mask]\n",
    "    return neg_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shrink dataframe so that we have one row per reviewer, with products as an array\n",
    "#n_samp is another hyperparameter that would be good to optimise. Perhaps we could just look at popular products?\n",
    "a_shrink = a.groupby('reviewerID')['prodID'].apply(np.array).rename('prodIDs').reset_index()\n",
    "a_shrink['negative_prodIDs'] = a_shrink['prodIDs'].apply(lambda x: negsamp_vectorized_bsearch(x, max(prod_index.values()), n_samp=2*len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>prodID</th>\n",
       "      <th>purchase_flag</th>\n",
       "      <th>genreID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewerID  prodID  purchase_flag  genreID\n",
       "0           0     0.0              1        0\n",
       "1           1     0.0              1        0\n",
       "2           2     0.0              1        0\n",
       "3           3     0.0              1        0\n",
       "4           4     0.0              1        0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = a_shrink.apply(lambda x: pd.Series(x['negative_prodIDs']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'prodID'\n",
    "a_shrink = a_shrink.drop(['prodIDs','negative_prodIDs'], axis=1).join(s)\n",
    "a_shrink['purchase_flag'] = 0\n",
    "a = pd.concat([a[['reviewerID', 'prodID', 'purchase_flag']], a_shrink], ignore_index=True)\n",
    "a = a.merge(prod_genre, how='inner', on='prodID')\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.sort_values(['reviewerID', 'prodID'], ascending=[True, True]).reset_index()[['reviewerID', 'prodID', 'genreID', 'purchase_flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>prodID</th>\n",
       "      <th>genreID</th>\n",
       "      <th>purchase_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2907.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3557.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10526.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewerID   prodID  genreID  purchase_flag\n",
       "0           0      0.0        0              1\n",
       "1           0   1210.0        9              0\n",
       "2           0   2907.0        0              0\n",
       "3           0   3557.0       12              1\n",
       "4           0  10526.0       12              0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_pickle('merged_album_data_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prodID\n",
       "36161.0    1\n",
       "12050.0    1\n",
       "12056.0    1\n",
       "12055.0    1\n",
       "12054.0    1\n",
       "Name: genreID, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check all products are 1-1 with genres\n",
    "a.groupby('prodID')['genreID'].nunique().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "#create a custom data dataset / dataloader\n",
    "class music_dataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        xy = np.load('merged_album_data_final')\n",
    "        self.u = np.array(xy.iloc[:,0:1])\n",
    "        self.p = np.array(xy.iloc[:,1:2])\n",
    "        self.g = np.array(xy.iloc[:,2:3])\n",
    "        self.upg = np.array(xy.drop(xy.columns[3],axis=1))\n",
    "        self.y = np.array(xy.iloc[:,3:])\n",
    "    def __len__(self):\n",
    "        return len(self.upg)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.upg[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://forums.fast.ai/t/lesson-4-advanced-discussion/30319/127\n",
    "from torch.nn import Module, Embedding, BCELoss\n",
    "from torch.optim import *\n",
    "from torch.autograd import Variable\n",
    "import torch \n",
    "\n",
    "def get_embs(ni, nf):\n",
    "    \"Create an embedding layer.\"\n",
    "    emb = torch.nn.Embedding(ni, nf)\n",
    "    # See https://arxiv.org/abs/1711.09160\n",
    "    emb.weight.data.uniform_(0,0.05)\n",
    "    return emb\n",
    "\n",
    "class EmbeddingModel(Module):\n",
    "    #initiate the weights and biases of user and product.\n",
    "    #these need to be leared through forward pass\n",
    "    def __init__(self, n_dims, n_users, n_items, n_genres):\n",
    "        super(EmbeddingModel, self).__init__()\n",
    "        (self.u_weight, self.i_weight, self.g_weight, self.u_bias, self.i_bias, self.g_bias) = [get_embs(*o) for o in [\n",
    "            (n_users, n_dims), #user weights\n",
    "            (n_items, n_dims), #product weights\n",
    "            (n_genres, n_dims), #genre weights\n",
    "            (n_users,1), #user bias\n",
    "            (n_items,1), #product bias\n",
    "            (n_genres,1)]] #genre bias\n",
    "    def forward(self, users, items, genres):\n",
    "        matmul = self.u_weight(users)* self.i_weight(items)* self.g_weight(genres)\n",
    "        out = matmul.sum(1) + self.u_bias(users).squeeze() + self.i_bias(items).squeeze() + self.g_bias(genres).squeeze()\n",
    "        #run output through a sigmoid\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "class CyclicLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]\n",
    "    \n",
    "def triangular(step_size, max_lr, method='triangular', gamma=0.99):\n",
    "    def scheduler(epoch, base_lr):\n",
    "        period = 2 * step_size\n",
    "        cycle = math.floor(1 + epoch/period)\n",
    "        x = abs(epoch/step_size - 2*cycle + 1)\n",
    "        delta = (max_lr - base_lr)*max(0, (1 - x))            \n",
    "        return base_lr + delta\n",
    "        \n",
    "    return scheduler \n",
    "\n",
    "def cosine(t_max, eta_min=0):  \n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + math.cos(math.pi*t/t_max))/2\n",
    "    \n",
    "    return scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6985642910003662\n",
      "0.6856696009635925\n",
      "0.6475222110748291\n",
      "0.7201673984527588\n",
      "0.6505962014198303\n",
      "0.5592682361602783\n",
      "0.6675215363502502\n",
      "0.6794180274009705\n",
      "0.6650784015655518\n",
      "0.5420235395431519\n",
      "0.5913771986961365\n",
      "0.6471108198165894\n",
      "0.6252194046974182\n",
      "0.658309817314148\n",
      "0.60185706615448\n",
      "0.6368136405944824\n",
      "0.5185902714729309\n",
      "0.6065595746040344\n",
      "0.5565740466117859\n",
      "0.5480939149856567\n",
      "0.5912162065505981\n",
      "0.5625611543655396\n",
      "0.6747888326644897\n",
      "0.6204331517219543\n",
      "0.5588315725326538\n",
      "0.5963636636734009\n",
      "0.5866166949272156\n",
      "0.5327626466751099\n",
      "0.5914582014083862\n",
      "0.5689964294433594\n",
      "0.6040873527526855\n",
      "0.691055178642273\n",
      "0.6297612190246582\n",
      "0.6609615087509155\n",
      "0.5465720295906067\n",
      "0.5600336790084839\n",
      "0.568292498588562\n",
      "0.5567008852958679\n",
      "0.6060009598731995\n",
      "0.59093177318573\n",
      "0.5493320226669312\n",
      "0.5169522166252136\n",
      "0.5457373261451721\n",
      "0.5828155875205994\n",
      "0.6113525032997131\n",
      "0.6144486665725708\n",
      "0.5834595561027527\n",
      "0.5167630314826965\n",
      "0.5106644034385681\n",
      "0.4873962998390198\n",
      "0.5970523953437805\n",
      "0.5566437840461731\n",
      "0.6341115236282349\n",
      "0.4643789827823639\n",
      "0.5205828547477722\n",
      "0.6139256358146667\n",
      "0.5561969876289368\n",
      "0.5806984901428223\n",
      "0.5723567605018616\n",
      "0.569252073764801\n",
      "0.5698159337043762\n",
      "0.6533451080322266\n",
      "0.5866637229919434\n",
      "0.5471977591514587\n",
      "0.6015503406524658\n",
      "0.5645988583564758\n",
      "0.5713302493095398\n",
      "0.5686810612678528\n",
      "0.4953595995903015\n",
      "0.5781025886535645\n",
      "0.5340753197669983\n",
      "0.5928289890289307\n",
      "0.47798094153404236\n",
      "0.5625473260879517\n",
      "0.5401867032051086\n",
      "0.5721814632415771\n",
      "0.5311051607131958\n",
      "0.6025360822677612\n",
      "0.5873525738716125\n",
      "0.6378908753395081\n",
      "0.5208232402801514\n",
      "0.47210919857025146\n",
      "0.5097817182540894\n",
      "0.6049337387084961\n",
      "0.6610414981842041\n",
      "0.6187818646430969\n",
      "0.7496652603149414\n",
      "0.5550756454467773\n",
      "0.5741044282913208\n",
      "0.6333831548690796\n",
      "0.6263948082923889\n",
      "0.6117196083068848\n",
      "0.6202118992805481\n",
      "0.5385518074035645\n",
      "0.48792433738708496\n",
      "0.5496766567230225\n",
      "0.5415096879005432\n",
      "0.5228862166404724\n",
      "0.6179893612861633\n",
      "0.5330744981765747\n",
      "0.5577274560928345\n",
      "0.5262163877487183\n",
      "0.5173724889755249\n",
      "0.5379003286361694\n",
      "0.5584285259246826\n",
      "0.6036255359649658\n",
      "0.5660395622253418\n",
      "0.5578341484069824\n",
      "0.5177962779998779\n",
      "0.5533478260040283\n",
      "0.5728996992111206\n",
      "0.6532219648361206\n",
      "0.6076932549476624\n",
      "0.5912415981292725\n",
      "0.6348952651023865\n",
      "0.4688992202281952\n",
      "0.5746086239814758\n",
      "0.6316208243370056\n",
      "0.6786192655563354\n",
      "0.5735654830932617\n",
      "0.5976319909095764\n",
      "0.567632794380188\n",
      "0.5462335348129272\n",
      "0.5105758309364319\n",
      "0.6127297878265381\n",
      "0.6389355063438416\n",
      "0.4666154682636261\n",
      "0.5502062439918518\n",
      "0.5849530100822449\n",
      "0.601334810256958\n",
      "0.5592994093894958\n",
      "0.5397616624832153\n",
      "0.5685126185417175\n",
      "0.5403234958648682\n",
      "0.6524303555488586\n",
      "0.5831962823867798\n",
      "0.5861988067626953\n",
      "0.5101677179336548\n",
      "0.6813640594482422\n",
      "0.6403429508209229\n",
      "0.6186833381652832\n",
      "0.5018594861030579\n",
      "0.5330307483673096\n",
      "0.534037172794342\n",
      "0.6746015548706055\n",
      "0.6109752058982849\n",
      "0.6060061454772949\n",
      "0.5749435424804688\n",
      "0.533193826675415\n",
      "0.5086084008216858\n",
      "0.6063670516014099\n",
      "0.581741452217102\n",
      "0.6160080432891846\n",
      "0.47663459181785583\n",
      "0.5169209241867065\n",
      "0.512229859828949\n",
      "0.6650665402412415\n",
      "0.5697435736656189\n",
      "0.5837038159370422\n",
      "0.550560712814331\n",
      "0.6596911549568176\n",
      "0.5369684100151062\n",
      "0.6515079140663147\n",
      "0.6217154264450073\n",
      "0.4639758765697479\n",
      "0.46569347381591797\n",
      "0.5961732268333435\n",
      "0.6053042411804199\n",
      "0.6728352308273315\n",
      "0.499318391084671\n",
      "0.5484951734542847\n",
      "0.5497579574584961\n",
      "0.5136173963546753\n",
      "0.629559338092804\n",
      "0.5414074063301086\n",
      "0.5959810614585876\n",
      "0.5637216567993164\n",
      "0.4833093583583832\n",
      "0.5238132476806641\n",
      "0.5511845350265503\n",
      "0.5298868417739868\n",
      "0.5379174947738647\n",
      "0.6168569326400757\n",
      "0.49243196845054626\n",
      "0.6627182960510254\n",
      "0.6671724319458008\n",
      "0.5045803189277649\n",
      "0.5665910840034485\n",
      "0.6451159715652466\n",
      "0.5094156265258789\n",
      "0.5265774130821228\n",
      "0.6293215155601501\n",
      "0.6019522547721863\n",
      "0.5759526491165161\n",
      "0.520590603351593\n",
      "0.6193219423294067\n",
      "0.5574512481689453\n",
      "0.5707676410675049\n",
      "0.5330728888511658\n",
      "0.5263569355010986\n",
      "0.4952148497104645\n",
      "0.6641557812690735\n",
      "0.515096127986908\n",
      "0.5417460799217224\n",
      "0.5993489623069763\n",
      "0.5280455946922302\n",
      "0.6018025279045105\n",
      "0.5399127006530762\n",
      "0.5273464322090149\n",
      "0.6033518314361572\n",
      "0.5004997849464417\n",
      "0.5321309566497803\n",
      "0.5709223747253418\n",
      "0.4694949984550476\n",
      "0.5657415986061096\n",
      "0.5052555203437805\n",
      "0.5286954045295715\n",
      "0.5947892069816589\n",
      "0.5133327841758728\n",
      "0.5708956718444824\n",
      "0.5598777532577515\n",
      "0.43358346819877625\n",
      "0.5222107172012329\n",
      "0.7114976644515991\n",
      "0.5388408303260803\n",
      "0.4994599223136902\n",
      "0.5612115859985352\n",
      "0.5125559568405151\n",
      "0.605515718460083\n",
      "0.6346619725227356\n",
      "0.5705447196960449\n",
      "0.5346782803535461\n",
      "0.5546789169311523\n",
      "0.6652995944023132\n",
      "0.5504849553108215\n",
      "0.6290819048881531\n",
      "0.6386479139328003\n",
      "0.5019505620002747\n",
      "0.5906796455383301\n",
      "0.5605325102806091\n",
      "0.6325823068618774\n",
      "0.5890721082687378\n",
      "0.5672202110290527\n",
      "0.5802628993988037\n",
      "0.5456350445747375\n",
      "0.5872886180877686\n",
      "0.6132742166519165\n",
      "0.5231197476387024\n",
      "0.4581436812877655\n",
      "0.6180351376533508\n",
      "0.5817792415618896\n",
      "0.5944234132766724\n",
      "0.5972465872764587\n",
      "0.525593101978302\n",
      "0.5218664407730103\n",
      "0.5601431727409363\n",
      "0.6292665600776672\n",
      "0.566116452217102\n",
      "0.5575164556503296\n",
      "0.5006251931190491\n",
      "0.611420214176178\n",
      "0.5516865849494934\n",
      "0.6108572483062744\n",
      "0.5479964017868042\n",
      "0.5758917927742004\n",
      "0.5937143564224243\n",
      "0.6036543846130371\n",
      "0.5839594006538391\n",
      "0.5833152532577515\n",
      "0.6346632242202759\n",
      "0.5945196151733398\n",
      "0.6162798404693604\n",
      "0.5604276061058044\n",
      "0.5358230471611023\n",
      "0.5798326730728149\n",
      "0.598560094833374\n",
      "0.6127141714096069\n",
      "0.5664146542549133\n",
      "0.5268344879150391\n",
      "0.5487310886383057\n",
      "0.5570052266120911\n",
      "0.5213258266448975\n",
      "0.5418537259101868\n",
      "0.6966016292572021\n",
      "0.5982699990272522\n",
      "0.5934639573097229\n",
      "0.5613511800765991\n",
      "0.6476965546607971\n",
      "0.5730346441268921\n",
      "0.6369873285293579\n"
     ]
    }
   ],
   "source": [
    "#we have a simple architecture now (embeddings). \n",
    "#we need to build a learner to train the model with\n",
    "# Loop over epochs\n",
    "#https://github.com/devforfu/pytorch_playground/blob/master/movielens.ipynb\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#load dataset and loader\n",
    "df_new = music_dataset()\n",
    "ds = DataLoader(df_new, batch_size=64, shuffle=True)\n",
    "\n",
    "#load model\n",
    "model = EmbeddingModel(n_dims=40, n_users=len(np.unique(df_new.u)),\n",
    "           n_items=len(np.unique(df_new.p)), n_genres=len(genre_index))\n",
    "#loss\n",
    "lr=1e-2\n",
    "loss_func = BCELoss()\n",
    "max_epochs = 1\n",
    "optimizer = Adam(model.parameters(),lr=lr,weight_decay=1e-5)\n",
    "iterations_per_epoch = len(ds)\n",
    "scheduler = CyclicLR(optimizer, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/10))\n",
    "optimizer.zero_grad()\n",
    "full_loss_df = []\n",
    "loss_values = []\n",
    "iteration = 0\n",
    "for epoch in range(max_epochs):\n",
    "    # Training\n",
    "    loss= 0.\n",
    "    for local_index, local_batch in enumerate(ds, 0):\n",
    "        iteration += 1\n",
    "        loss= 0.\n",
    "        #pass in the indices of the batch user and prod \n",
    "        output = model.forward(local_batch[0][:,0:1].squeeze(1).long(),\n",
    "                               local_batch[0][:,1:2].squeeze(1).long(),\n",
    "                               local_batch[0][:,2:3].squeeze(1).long())\n",
    "        #compare outputs of batch with n=64 to label and compute the loss\n",
    "        labels = local_batch[1].float()\n",
    "        #calculate the loss\n",
    "        loss = loss_func(output, labels.squeeze(1))\n",
    "        scheduler.step()\n",
    "        #update the parameters using backpropogation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss_values.append(loss.data.item())\n",
    "        if (len(loss_values) % 100 == 0) | (len(loss_values) == 1):\n",
    "            print(loss.data.item())\n",
    "    #load full dataset and run forward pass\n",
    "    output_full = Variable(model.forward(torch.tensor(df_new.upg[:,0:1].squeeze(1)).long(),\n",
    "                                 torch.tensor(df_new.upg[:,1:2].squeeze(1)).long(),\n",
    "                                 torch.tensor(df_new.upg[:,2:3].squeeze(1)).long()), requires_grad=False)\n",
    "    full_loss = loss_func(output_full, Variable(torch.tensor(df_new.y).float().squeeze(1)))        #calculate the loss\n",
    "    full_loss_df.append(full_loss.data.item())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_values), len(loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'dotprod_scratch_final')\n",
    "model = torch.load('dotprod_scratch_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element wise multiply product and genre tensors together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod_genre_combo(i_index, g_index):\n",
    "    prod_tensor = model['i_weight.weight'][i_index].double()\n",
    "    genre_tensor = model['g_weight.weight'][g_index].double()\n",
    "    return prod_tensor*genre_tensor\n",
    "prod_genre_combo_tensor = torch.empty(size=(len(prod_genre), 40))\n",
    "for i in range(len(prod_genre)-1):\n",
    "    prod_genre_combo_tensor[i] = prod_genre_combo(i,prod_genre['genreID'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine similarity of albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_matrix = pd.DataFrame(cosine_similarity(\n",
    "            X=prod_genre_combo_tensor),\n",
    "            index=list(music_index.keys()))\n",
    "similarity_matrix.columns = list(music_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_albums(album, n):\n",
    "    similar_items = pd.DataFrame(similarity_matrix.loc[album])\n",
    "    similar_items.columns = ['score']\n",
    "    similar_items = similar_items.sort_values('score', ascending=False)\n",
    "    similar_items = similar_items.head(n).reset_index()\n",
    "    similar_items = similar_items.rename(index=str, columns={'index': 'item_id'})\n",
    "    return similar_items.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_similar_albums('Britney', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_index = dict(zip(df_music['title'], df_music['prodID']))\n",
    "\n",
    "#from fastai - torch pca\n",
    "def _pca(x, k=2):\n",
    "    \"Compute PCA of `x` with `k` dimensions.\"\n",
    "    x = x-torch.mean(x,0)\n",
    "    U,S,V = torch.svd(x.t())\n",
    "    return torch.mm(x,U[:,:k])\n",
    "torch.Tensor.pca = _pca\n",
    "\n",
    "def generate_embedding_plot(top=500):\n",
    "    g = df_music.groupby('title')['overall'].count()\n",
    "    #grab top music\n",
    "    top_music = g.sort_values(ascending=False).index.values[:top]\n",
    "    top_music_w = items_w[[music_index[x] for x in top_music.tolist()]]\n",
    "    #reduce the dimensions from 40 to 2\n",
    "    top_music_w_pca = top_music_w.detach().pca(2)\n",
    "    fac0,fac1 = top_music_w_pca.t()\n",
    "    music_comp = [(f, i) for f,i in zip(fac0, top_music)]\n",
    "    \n",
    "    #produce plot\n",
    "    idxs = np.random.choice(len(top_music), 300, replace=False)\n",
    "    idxs = list(range(100))\n",
    "    X = fac0[idxs]\n",
    "    Y = fac1[idxs]\n",
    "    plt.figure(figsize=(25,25))\n",
    "    plt.scatter(X, Y,clip_on=True)\n",
    "    for i, x, y in zip(top_music[idxs], X, Y):\n",
    "        plt.text(x,y,i, color=np.random.rand(3)*0.7, fontsize=13,clip_on=True)\n",
    "generate_embedding_plot()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_w = model['g_weight.weight']\n",
    "g = df_music.groupby('title')['overall'].count()\n",
    "#grab top music\n",
    "top_genres_w = genres_w[[genre_index[x] for x in genre_list]]\n",
    "#reduce the dimensions from 40 to 2\n",
    "top_genres_w_pca = top_genres_w.detach().pca(2)\n",
    "fac0,fac1 = top_genres_w_pca.t()\n",
    "\n",
    "#produce plot\n",
    "X = fac0\n",
    "Y = fac1\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(X, Y,clip_on=True)\n",
    "for i, x, y in zip(genre_list, X, Y):\n",
    "    plt.text(x,y,i, color=np.random.rand(3)*0.7, fontsize=13,clip_on=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
